{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "786c3d10-510f-42b2-bdc5-6486bd1e07a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI API Key exists and begins sk-proj-\n",
      "Anthropic API Key exists and begins sk-ant-\n",
      "Google API Key not set\n",
      "Serp API Key exists and begins 94a308d7\n",
      "All necessary libraries imported and API Key environment variables should be set.\n",
      "Search tool (SerpAPI) initialized successfully.\n",
      "LLM (ChatOpenAI - gpt-4o-mini) initialized successfully.\n",
      "Agent created with ReAct paradigm and available tools.\n",
      "Agent Executor created. Ready to run queries!\n",
      "Chat history initialized.\n"
     ]
    }
   ],
   "source": [
    "# Cell 1: Import Libraries and Set API Keys\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import ChatOpenAI # For interacting with OpenAI's LLMs\n",
    "from langchain.agents import AgentExecutor, create_react_agent # Core components for building agents\n",
    "from langchain_core.prompts import PromptTemplate # For defining how the LLM should respond\n",
    "from langchain_community.utilities import SerpAPIWrapper # For using SerpAPI to perform web searches\n",
    "from langchain.tools import Tool # A general wrapper to make functions usable by the agent\n",
    "from langchain_core.messages import HumanMessage, AIMessage # For managing conversation history\n",
    "\n",
    "# --- Set your API Keys from .env ---\n",
    "load_dotenv(override=True)\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "anthropic_api_key = os.getenv('ANTHROPIC_API_KEY')\n",
    "google_api_key = os.getenv('GOOGLE_API_KEY')\n",
    "serp_api_key = os.getenv('SERPAPI_API_KEY')\n",
    "\n",
    "if openai_api_key:\n",
    "    print(f\"OpenAI API Key exists and begins {openai_api_key[:8]}\")\n",
    "else:\n",
    "    print(\"OpenAI API Key not set\")\n",
    "    \n",
    "if anthropic_api_key:\n",
    "    print(f\"Anthropic API Key exists and begins {anthropic_api_key[:7]}\")\n",
    "else:\n",
    "    print(\"Anthropic API Key not set\")\n",
    "\n",
    "if google_api_key:\n",
    "    print(f\"Google API Key exists and begins {google_api_key[:8]}\")\n",
    "else:\n",
    "    print(\"Google API Key not set\")\n",
    "\n",
    "if serp_api_key:\n",
    "    print(f\"Serp API Key exists and begins {serp_api_key[:8]}\")\n",
    "else:\n",
    "    print(\"Serp API Key not set\")\n",
    "   \n",
    "print(\"All necessary libraries imported and API Key environment variables should be set.\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Cell 2: Define the Agent's Tool(s)\n",
    "\n",
    "# Initialize the SerpAPIWrapper. This object knows how to make requests to SerpAPI.\n",
    "try:\n",
    "    search = SerpAPIWrapper()\n",
    "    # Define a list of tools that our agent can use.\n",
    "    # Each tool is represented by a LangChain 'Tool' object.\n",
    "    tools = [\n",
    "        Tool(\n",
    "            name=\"Search\", # A unique, descriptive name for the tool. The LLM will refer to it by this name.\n",
    "            func=search.run, # The Python function that gets called when this tool is used (e.g., search.run('query')).\n",
    "            description=\"\"\"\n",
    "            Useful for when you need to answer questions about current events,\n",
    "            up-to-date facts, or when you need to get factual information that\n",
    "            might change over time. Input should be a concise question for the search engine.\n",
    "            \"\"\" # This description is CRITICAL. The LLM reads this to decide WHEN to use the tool.\n",
    "        )\n",
    "    ]\n",
    "    print(\"Search tool (SerpAPI) initialized successfully.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error initializing SerpAPI: {e}.\")\n",
    "    print(\"Please ensure your SERPAPI_API_KEY is correctly set in Cell 1 and is valid.\")\n",
    "    print(\"The agent might not be able to perform web searches without a working SerpAPI key.\")\n",
    "    tools = [] # If SerpAPI fails, we set tools to an empty list so the program can still run (but with limited functionality).\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Cell 3: Initialize the Large Language Model (LLM)\n",
    "\n",
    "# We initialize a ChatOpenAI model, which is designed for conversational interactions.\n",
    "# We're using \"gpt-4o\", a powerful and versatile model by OpenAI.\n",
    "# `temperature=0` makes the model's responses more deterministic and factual,\n",
    "# which is generally preferred for agents performing specific tasks, reducing 'hallucinations'.\n",
    "try:\n",
    "    llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "    print(\"LLM (ChatOpenAI - gpt-4o-mini) initialized successfully.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error initializing OpenAI LLM: {e}.\")\n",
    "    print(\"Please ensure your OPENAI_API_KEY is correctly set in Cell 1 and is valid, and you have an active internet connection.\")\n",
    "    print(\"Cannot proceed without a working LLM.\")\n",
    "    llm = None # Set LLM to None if initialization fails, to prevent further errors.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Cell 4: Create the Agent and its Prompt Template\n",
    "\n",
    "# Define the agent's prompt template.\n",
    "# This template is passed to the LLM and guides its reasoning process.\n",
    "# It explicitly lists the tools, defines the expected \"Thought/Action/Observation\" format,\n",
    "# and includes placeholders for user input and chat history.\n",
    "prompt_template = PromptTemplate.from_template(\"\"\"\n",
    "You are a helpful and intelligent AI assistant.\n",
    "If the answer is immediately known without needing a tool, provide the Final Answer directly.\n",
    "Otherwise, you have access to the following tools:\n",
    "{tools}\n",
    "Use the following format:\n",
    "Question: the input question you must answer\n",
    "Thought: you should always think about what to do, and if you need to use a tool.\n",
    "Action: the action to take, should be one of [{tool_names}] \n",
    "Action Input: the input to the action\n",
    "Observation: the result of the action\n",
    "... (this Thought/Action/Action Input/Observation can repeat N times if needed)\n",
    "Thought: I now know the final answer or have gathered enough information.\n",
    "Final Answer: the final, concise answer to the original input question\n",
    "Begin!\n",
    "Previous conversation history:\n",
    "{chat_history}\n",
    "{agent_scratchpad}\n",
    "Question: {input} \n",
    "Thought: \n",
    "\"\"\")\n",
    "\n",
    "# Create the agent itself using the ReAct (Reasoning + Acting) paradigm.\n",
    "# `create_react_agent` is a LangChain helper that sets up the LLM to follow the ReAct prompt structure.\n",
    "# It takes the LLM, the list of tools, and the prompt template as input.\n",
    "if llm and tools: # Ensure LLM and tools are successfully initialized before creating the agent\n",
    "    agent = create_react_agent(llm, tools, prompt_template)\n",
    "    print(\"Agent created with ReAct paradigm and available tools.\")\n",
    "else:\n",
    "    print(\"Warning: Agent could not be fully created due in Cell 3 (missing LLM) or Cell 2 (missing tools).\")\n",
    "    # As a fallback, if LLM is available but tools are not, we create a basic LLMChain.\n",
    "    # This agent won't be able to use tools, but can still answer from its base knowledge.\n",
    "    if llm:\n",
    "        from langchain.chains import LLMChain\n",
    "        from langchain.prompts import ChatPromptTemplate\n",
    "        simple_prompt = ChatPromptTemplate.from_messages([\n",
    "            (\"system\", \"You are a helpful AI assistant. Answer questions based on your internal knowledge.\"),\n",
    "            (\"human\", \"{input}\")\n",
    "        ])\n",
    "        agent = LLMChain(llm=llm, prompt=simple_prompt)\n",
    "        print(\"Agent created as a basic LLMChain (no tool use functionality).\")\n",
    "    else:\n",
    "        agent = None # Agent cannot be created without an LLM.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Cell 5: Create the Agent Executor and Initialize Chat History\n",
    "\n",
    "# The AgentExecutor is responsible for running the agent.\n",
    "# It takes the agent itself and the list of available tools.\n",
    "# `verbose=True` is extremely useful for development, as it prints out the agent's\n",
    "# internal 'Thought', 'Action', 'Action Input', and 'Observation' steps.\n",
    "# `handle_parsing_errors=True` helps the agent recover if the LLM doesn't perfectly\n",
    "# follow the ReAct output format (e.g., misspellings).\n",
    "# `max_iterations=5` sets a limit on how many Thought/Action/Observation steps the\n",
    "# agent can take before giving up, preventing infinite loops.\n",
    "if agent and tools: # Ensure agent and tools were successfully created in previous cells\n",
    "    agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True, handle_parsing_errors=True, max_iterations=5)\n",
    "    print(\"Agent Executor created. Ready to run queries!\")\n",
    "else:\n",
    "    print(\"Agent Executor not created as agent or tools are not properly initialized. Cannot run queries.\")\n",
    "    agent_executor = None # Set to None if initialization failed.\n",
    "\n",
    "# Initialize an empty list to store our conversation history.\n",
    "# This list will be updated with each user query and agent response,\n",
    "# allowing the agent to maintain context across multiple turns.\n",
    "chat_history = []\n",
    "\n",
    "print(\"Chat history initialized.\")\n",
    "\n",
    "\n",
    "\n",
    "# Cell 6: Define a Helper Function to Run Queries\n",
    "\n",
    "# This function will encapsulate the logic for sending a query to the agent\n",
    "# and managing the conversation history.\n",
    "def run_agent_query(query: str):\n",
    "    global chat_history # We use 'global' to indicate that we want to modify the chat_history list defined outside this function.\n",
    "\n",
    "    if agent_executor: # Ensure the executor was successfully initialized\n",
    "        print(f\"\\n--- User Query: {query} ---\")\n",
    "        try:\n",
    "            # Invoke the agent executor.\n",
    "            # We pass the current user 'input' and the 'chat_history' for context.\n",
    "            response = agent_executor.invoke({\"input\": query, \"chat_history\": chat_history})\n",
    "            # Extract the final answer from the response dictionary.\n",
    "            final_answer = response.get('output', \"No output generated.\")\n",
    "\n",
    "            print(f\"\\nAgent's Final Answer: {final_answer}\")\n",
    "\n",
    "            # Update the chat history for the next turn.\n",
    "            # We append a HumanMessage (our query) and an AIMessage (the agent's response).\n",
    "            chat_history.append(HumanMessage(content=query))\n",
    "            chat_history.append(AIMessage(content=final_answer))\n",
    "\n",
    "            return final_answer\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred during agent execution: {e}\")\n",
    "            return \"Sorry, I encountered an error trying to process your request.\"\n",
    "    else:\n",
    "        print(\"Agent Executor is not initialized. Cannot run query.\")\n",
    "        return \"Agent is not ready to respond.\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1f9182e0-f100-4d1d-8dce-a1884ae9c30a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Running Agent for Example Queries ---\n",
      "\n",
      "--- User Query: What is the capital of India? ---\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThe capital of India is New Delhi. \n",
      "Final Answer: New Delhi\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "Agent's Final Answer: New Delhi\n",
      "\n",
      "--- User Query: As of year 2025, What is the population of Houston, Texas? ---\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mI need to find the most current population estimate for Houston, Texas, as of the year 2025. \n",
      "Action: Search \n",
      "Action Input: \"Houston Texas population estimate 2025\" \u001b[0m\u001b[36;1m\u001b[1;3mHouston's population in 2025 is 2,319,119, with a metro area projection of 6.89 million. The city leads in STEM degrees, with 49.1% of graduates specializing in science and engineering. Harris County cut migration losses by half during the pandemic, losing 16,000 residents annually by 2022.\u001b[0m\u001b[32;1m\u001b[1;3mFinal Answer: The population of Houston, Texas, in 2025 is estimated to be 2,319,119.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "Agent's Final Answer: The population of Houston, Texas, in 2025 is estimated to be 2,319,119.\n",
      "\n",
      "--- User Query: What are the major sports teams in this city? ---\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mTo provide an accurate answer, I need to clarify which city you are referring to. Since the previous conversation mentioned Houston, Texas, I will assume you are asking about Houston. \n",
      "\n",
      "Action: Search  \n",
      "Action Input: \"major sports teams in Houston Texas\"  \u001b[0m\u001b[36;1m\u001b[1;3m{'type': 'organic_result'}\u001b[0m\u001b[32;1m\u001b[1;3mAction: Search  \n",
      "Action Input: \"major sports teams in Houston Texas\"  \u001b[0m\u001b[36;1m\u001b[1;3m{'type': 'organic_result'}\u001b[0m\u001b[32;1m\u001b[1;3mAction: Search  \n",
      "Action Input: \"major sports teams in Houston Texas\"  \u001b[0m\u001b[36;1m\u001b[1;3m{'type': 'organic_result'}\u001b[0m\u001b[32;1m\u001b[1;3mAction: Search  \n",
      "Action Input: \"major sports teams in Houston Texas\"  \u001b[0m\u001b[36;1m\u001b[1;3m{'type': 'organic_result'}\u001b[0m\u001b[32;1m\u001b[1;3mAction: Search  \n",
      "Action Input: \"major sports teams in Houston Texas\"  \u001b[0m\u001b[36;1m\u001b[1;3m{'type': 'organic_result'}\u001b[0m\u001b[32;1m\u001b[1;3m\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "Agent's Final Answer: Agent stopped due to iteration limit or time limit.\n",
      "\n",
      "--- User Query: What is the latest news on AI safety regulations as of today? ---\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mI need to find the most recent information regarding AI safety regulations, as this is a current topic that may have updates. \n",
      "\n",
      "Action: Search \n",
      "Action Input: \"latest news on AI safety regulations October 2023\" \n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m['Executive Order 14110 of October 30, 2023. Safe, Secure, and Trustworthy Development and Use of Artificial Intelligence.', 'On the list of rescinded Executive Orders is the October 2023 Executive Order on the Safe, Secure, and Trustworthy Development and Use of Artificial ...', 'In October 2023, President Biden issued Executive Order 14110 on “Safe, Secure, and Trustworthy AI”, directing a broad range of AI oversight ...', 'The directive, issued in October 2023, added guardrails for AI developers and bolstered guidance for businesses looking to adopt the technology.', 'This order revokes certain existing AI policies and directives that act as barriers to American AI innovation, clearing a path for the United States to act ...', 'On September 12, 2023, the US Senate held public hearings regarding AI,12 which laid out potential forthcoming AI regulations. Possible ...', 'On October 30, 2023, the Biden Administration released Executive Order (E.O.) 14110 on Safe, Secure, and Trustworthy Development and Use of ...', 'BCLP actively tracks the proposed, failed and enacted AI regulatory bills from across the United States to help our clients stay informed.', 'On October 24, 2024, the White House published a National Security Memorandum on the use of AI models and AI-enabled technologies in national ...', 'In October 2023, President Joe Biden issued a broad executive order on AI (AI Order), which the administration touted as a vehicle to establish ...']\u001b[0m\u001b[32;1m\u001b[1;3mAction: Search \n",
      "Action Input: \"latest news on AI safety regulations October 2023\" \n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m['Executive Order 14110 of October 30, 2023. Safe, Secure, and Trustworthy Development and Use of Artificial Intelligence.', 'On the list of rescinded Executive Orders is the October 2023 Executive Order on the Safe, Secure, and Trustworthy Development and Use of Artificial ...', 'In October 2023, President Biden issued Executive Order 14110 on “Safe, Secure, and Trustworthy AI”, directing a broad range of AI oversight ...', 'The directive, issued in October 2023, added guardrails for AI developers and bolstered guidance for businesses looking to adopt the technology.', 'This order revokes certain existing AI policies and directives that act as barriers to American AI innovation, clearing a path for the United States to act ...', 'On September 12, 2023, the US Senate held public hearings regarding AI,12 which laid out potential forthcoming AI regulations. Possible ...', 'On October 30, 2023, the Biden Administration released Executive Order (E.O.) 14110 on Safe, Secure, and Trustworthy Development and Use of ...', 'BCLP actively tracks the proposed, failed and enacted AI regulatory bills from across the United States to help our clients stay informed.', 'On October 24, 2024, the White House published a National Security Memorandum on the use of AI models and AI-enabled technologies in national ...', 'In October 2023, President Joe Biden issued a broad executive order on AI (AI Order), which the administration touted as a vehicle to establish ...']\u001b[0m\u001b[32;1m\u001b[1;3mI have gathered enough information regarding the latest updates on AI safety regulations.\n",
      "\n",
      "Final Answer: In October 2023, President Biden issued Executive Order 14110, focusing on the \"Safe, Secure, and Trustworthy Development and Use of Artificial Intelligence.\" This order aims to establish comprehensive oversight for AI, adding guardrails for developers and providing guidance for businesses adopting AI technologies. It also revokes certain existing policies that hinder AI innovation in the U.S.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "Agent's Final Answer: In October 2023, President Biden issued Executive Order 14110, focusing on the \"Safe, Secure, and Trustworthy Development and Use of Artificial Intelligence.\" This order aims to establish comprehensive oversight for AI, adding guardrails for developers and providing guidance for businesses adopting AI technologies. It also revokes certain existing policies that hinder AI innovation in the U.S.\n",
      "\n",
      "--- All example interactions complete ---\n",
      "\n",
      "Final Full Chat History:\n",
      "HumanMessage: What is the capital of India?\n",
      "AIMessage: New Delhi\n",
      "HumanMessage: As of year 2025, What is the population of Houston, Texas?\n",
      "AIMessage: The population of Houston, Texas, in 2025 is estimated to be 2,319,119.\n",
      "HumanMessage: What are the major sports teams in this city?\n",
      "AIMessage: Agent stopped due to iteration limit or time limit.\n",
      "HumanMessage: What is the latest news on AI safety regulations as of today?\n",
      "AIMessage: In October 2023, President Biden issued Executive Order 14110, focusing on the \"Safe, Secure, and Trustworthy Development and Use of Artificial Intelligence.\" This order aims to establish comprehensive oversight for AI, adding guardrails for developers and providing guidance for businesses adopting AI technologies. It also revokes certain existing policies that hinder AI innovation in the U.S.\n"
     ]
    }
   ],
   "source": [
    "# Cell 7: Test Your Agent with Example Queries\n",
    "\n",
    "print(\"\\n--- Running Agent for Example Queries ---\")\n",
    "\n",
    "# --- Query 1: A simple factual question the LLM might know directly ---\n",
    "# The agent should respond quickly without needing the search tool.\n",
    "run_agent_query(\"What is the capital of India?\")\n",
    "\n",
    "# --- Query 2: A factual question requiring up-to-date information ---\n",
    "# The agent should recognize it needs current data and use the 'Search' tool.\n",
    "run_agent_query(\"As of year 2025, What is the population of Houston, Texas?\")\n",
    "\n",
    "# --- Query 3: A question leveraging previous context ---\n",
    "# The agent should understand \"this city\" refers to \"Houston\" from the previous turn.\n",
    "run_agent_query(\"What are the major sports teams in this city?\")\n",
    "\n",
    "# --- Query 4: A question about recent events ---\n",
    "# This will definitely trigger the 'Search' tool to find the latest information.\n",
    "run_agent_query(\"What is the latest news on AI safety regulations as of today?\")\n",
    "\n",
    "print(\"\\n--- All example interactions complete ---\")\n",
    "print(\"\\nFinal Full Chat History:\")\n",
    "# Loop through the entire chat_history to see the full conversation flow.\n",
    "for msg in chat_history:\n",
    "    print(f\"{type(msg).__name__}: {msg.content}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1426b523-0792-4c58-be9e-d3d0c36f1089",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "014e0f59-13d2-45a5-bb0e-bc73f62947a6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
